<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Inseop Chung</title>

    <meta name="author" content="Inseop Chung">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <!-- Profile Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Inseop Chung
                </p>
                <p>I'm a Staff Researcher at the AI Center of Samsung Electronics, where I work on various topics in computer vision and machine learning.
                </p>
                <p>
                  I received my PhD from <a href="https://convergence.snu.ac.kr/en/intl_inf_intro/">Graduate School of Convergence Science and Technology (GSCST), Department of Intelligence and Information</a> of <a href="https://en.snu.ac.kr">Seoul National University (SNU)</a> under the supervision of professor <a href="https://scholar.google.com/citations?user=h_8-1M0AAAAJ&hl=en">Nojun Kwak</a>. I was a member of the <a href="https://mipal.snu.ac.kr/mipal">Machine Intelligence and Pattern Analysis Lab (MIPAL)</a> led by Prof. Kwak. My research focuses on domain adaptation, domain generalization, test-time adaptation, object detection, semantic segmentation, knowledge distillation, and vision-language-action models.
                </p>
                <p style="text-align:center">
                  <a href="mailto:insupjung613@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=6bFY9FgAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/chung-inseop-0b3178231/?originalSubdomain=kr">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/inseopchung">GitHub</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- Research Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, and machine learning. My research focuses on making AI models more robust and adaptable to real-world scenarios through domain adaptation, domain generalization, and test-time adaptation. I also work on object detection, semantic segmentation, knowledge distillation, and vision-language-action models.
                </p>
              </td>
            </tr>
          </tbody></table>

          <!-- Education Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Education</h2>
                <p>
                  <strong>Ph.D.</strong> in Engineering, Seoul National University, 2019-2024<br>
                  Graduate School of Convergence Science and Technology, Department of Intelligence and Information<br>
                  Advisor: <a href="https://scholar.google.com/citations?user=h_8-1M0AAAAJ&hl=en">Nojun Kwak</a>
                </p>
                <p>
                  <strong>B.S.</strong> in Creative Technology Management & Computer Science, Yonsei University, 2012-2019<br>
                  Exchange Student Program at Technical University of Munich (2016-2017)
                </p>
              </td>
            </tr>
          </tbody></table>

          <!-- Work Experience Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Work Experience</h2>
                <p>
                  <strong>Staff Researcher</strong>, AI Center, Samsung Electronics, 2024.Dec.-Present<br>
                  Research on computer vision and machine learning
                </p>
                <p>
                  <strong>Staff Researcher</strong>, Samsung Advanced Institute of Technology (SAIT), Samsung Electronics, 2024.Mar-2024.Dec.<br>
                  Research on computer vision and machine learning
                </p>
                <p>
                  <strong>Research Intern</strong>, Qualcomm AI Research Korea, 2022.Jan-2022.Jul<br>
                  As a Deep Learning Research Intern, I worked on Few-Shot Learning (FSL) for Keyword Spotting (KWS), focusing on enabling models to recognize new keywords with minimal labeled examples. My contributions included developing and optimizing few-shot learning algorithms to improve robustness and efficiency in speech recognition tasks.
                </p>
                <p>
                  <strong>Research Intern</strong>, Naver Webtoons Corp., 2020.Jun-2020.Dec<br>
                  As a Deep Learning Research Intern, I worked on Unsupervised Domain Adaptation (UDA) for semantic segmentation, aiming to improve model generalization across different domains. My contributions included developing novel adaptation techniques to mitigate domain shifts and enhancing segmentation accuracy in diverse webtoon styles. Through this work, I gained hands-on experience in domain adaptation strategies and their practical applications in real-world datasets.
                </p>
              </td>
            </tr>
          </tbody></table>

          <!-- Publications Section Header -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>

          <!-- Publications List -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="mitigating_stop()" onmouseover="mitigating_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='mitigating_image'><img src='images/mitigate.jpeg' width="160"></div>
                  <img src='images/mitigate.jpeg' width="160">
                </div>
                <script type="text/javascript">
                  function mitigating_start() {
                    document.getElementById('mitigating_image').style.opacity = "1";
                  }

                  function mitigating_stop() {
                    document.getElementById('mitigating_image').style.opacity = "0";
                  }
                  mitigating_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2403.01344">
                  <span class="papertitle">Mitigating the Bias in the Model for Continual Test-Time Adaptation</span>
                </a>
                <br>
                <strong>Inseop Chung</strong>,
                Kyomin Hwang,
                Jayeon Yoo,
                Nojun Kwak
                <br>
                <em>arXiv</em>, 2024.Mar
                <br>
                <a href="https://arxiv.org/abs/2403.01344">arXiv</a>
                <p></p>
                <p>
                We propose a method to mitigate the bias in the model during continual test-time adaptation.
                </p>
              </td>
            </tr>

            <tr onmouseout="open_stop()" onmouseover="open_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='open_image'><img src='images/odg.jpg' width="160"></div>
                  <img src='images/odg.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function open_start() {
                    document.getElementById('open_image').style.opacity = "1";
                  }

                  function open_stop() {
                    document.getElementById('open_image').style.opacity = "0";
                  }
                  open_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2312.05141">
                  <span class="papertitle">Open Domain Generalization with a Single Network by Regularization Exploiting Pretrained Features</span>
                </a>
                <br>
                <strong>Inseop Chung</strong>,
                Kiyoon Yoo,
                Nojun Kwak
                <br>
                <em>ICLR 2024 Workshop</em>, 2024.May
                <br>
                <a href="https://arxiv.org/abs/2312.05141">arXiv</a>
                <p></p>
                <p>
                We propose a method for open domain generalization with a single network by regularization exploiting pretrained features.
                </p>
              </td>
            </tr>

            <tr onmouseout="what_stop()" onmouseover="what_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='what_image'><img src='images/cat_od.jpg' width="160"></div>
                  <img src='images/cat_od.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function what_start() {
                    document.getElementById('what_image').style.opacity = "1";
                  }

                  function what_stop() {
                    document.getElementById('what_image').style.opacity = "0";
                  }
                  what_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2312.08875">
                  <span class="papertitle">What, How, and When Should Object Detectors Update in Continually Changing Test Domains?</span>
                </a>
                <br>
                Jayeon Yoo,
                Dongkwan Lee,
                <strong>Inseop Chung</strong>,
                Donghyun Kim,
                Nojun Kwak
                <br>
                <em>CVPR</em>, 2024.Jun
                <br>
                <a href="https://arxiv.org/abs/2312.08875">arXiv</a>
                <p></p>
                <p>
                We investigate when and how object detectors should update in continually changing test domains.
                </p>
              </td>
            </tr>

            <tr onmouseout="end_stop()" onmouseover="end_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='end_image'><img src='images/e2e_od.jpg' width="160"></div>
                  <img src='images/e2e_od.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function end_start() {
                    document.getElementById('end_image').style.opacity = "1";
                  }

                  function end_stop() {
                    document.getElementById('end_image').style.opacity = "0";
                  }
                  end_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2205.08714">
                  <span class="papertitle">End-to-End Multi-Object Detection with a Regularized Mixture Model</span>
                </a>
                <br>
                Jaeyoung Yoo*,
                Hojun Lee*,
                Seunghyeon Seo,
                <strong>Inseop Chung</strong>,
                Nojun Kwak
                <br>
                <em>ICML</em>, 2023.Jul
                <br>
                <a href="https://arxiv.org/abs/2205.08714">arXiv</a>
                <p></p>
                <p>
                We propose an end-to-end multi-object detection method with a regularized mixture model.
                </p>
              </td>
            </tr>

            <tr onmouseout="exploiting_stop()" onmouseover="exploiting_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='exploiting_image'><img src='images/inter_pixel_uda.jpg' width="160"></div>
                  <img src='images/inter_pixel_uda.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function exploiting_start() {
                    document.getElementById('exploiting_image').style.opacity = "1";
                  }

                  function exploiting_stop() {
                    document.getElementById('exploiting_image').style.opacity = "0";
                  }
                  exploiting_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2110.10916">
                  <span class="papertitle">Exploiting Inter-pixel Correlations in Unsupervised Domain Adaptation for Semantic Segmentation</span>
                </a>
                <br>
                <strong>Inseop Chung</strong>,
                Jayeon Yoo,
                Nojun Kwak
                <br>
                <em>WACV 2023 Workshop (Best Paper Award)</em>, 2023.Jan
                <br>
                <a href="https://arxiv.org/abs/2110.10916">arXiv</a>
                <p></p>
                <p>
                We propose a method to exploit inter-pixel correlations in unsupervised domain adaptation for semantic segmentation.
                </p>
              </td>
            </tr>

            <tr onmouseout="xmas_stop()" onmouseover="xmas_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='xmas_image'><img src='images/x-mas.jpg' width="160"></div>
                  <img src='images/x-mas.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function xmas_start() {
                    document.getElementById('xmas_image').style.opacity = "1";
                  }

                  function xmas_stop() {
                    document.getElementById('xmas_image').style.opacity = "0";
                  }
                  xmas_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="#">
                  <span class="papertitle">X-MAS: Extremely Large-Scale Multi-Modal Sensor Dataset for Outdoor Surveillance in Real Environments</span>
                </a>
                <br>
                DongKi Noh,
                Chang Ki Sung,
                Taeyoung Uhm,
                Wooju Lee,
                Hyungtae Lim,
                Jaeseok Choi,
                Kyuewang Lee,
                Dasol Hong,
                Daeho Um,
                <strong>Inseop Chung</strong>,
                Hochul Shin,
                Min-Jung Kim,
                Hyoung-Rock Kim,
                Seung-Min Baek,
                Hyun Myung
                <br>
                <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2023.Jan
                <br>
                <p></p>
                <p>
                We present an extremely large-scale multi-modal sensor dataset for outdoor surveillance in real environments.
                </p>
              </td>
            </tr>

            <tr onmouseout="unsupervised_stop()" onmouseover="unsupervised_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='unsupervised_image'><img src='images/uda_od.jpg' width="160"></div>
                  <img src='images/uda_od.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function unsupervised_start() {
                    document.getElementById('unsupervised_image').style.opacity = "1";
                  }

                  function unsupervised_stop() {
                    document.getElementById('unsupervised_image').style.opacity = "0";
                  }
                  unsupervised_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2207.09656">
                  <span class="papertitle">Unsupervised Domain Adaptation for One-Stage Object Detector Using Offsets to the Bounding Box</span>
                </a>
                <br>
                Jayeon Yoo,
                <strong>Inseop Chung</strong>,
                Nojun Kwak
                <br>
                <em>ECCV</em>, 2022.Oct
                <br>
                <a href="https://arxiv.org/abs/2207.09656">arXiv</a>
                <p></p>
                <p>
                We propose a method for unsupervised domain adaptation for one-stage object detector using offsets to the bounding box.
                </p>
              </td>
            </tr>

            <tr onmouseout="dummy_stop()" onmouseover="dummy_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dummy_image'><img src='images/osks.jpg' width="160"></div>
                  <img src='images/osks.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function dummy_start() {
                    document.getElementById('dummy_image').style.opacity = "1";
                  }

                  function dummy_stop() {
                    document.getElementById('dummy_image').style.opacity = "0";
                  }
                  dummy_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2206.13691">
                  <span class="papertitle">Dummy Prototypical Networks for Few-Shot Open-Set Keyword Spotting</span>
                </a>
                <br>
                Byeonggeun Kim,
                Seunghan Yang,
                <strong>Inseop Chung</strong>,
                Simyung Chang
                <br>
                <em>INTERSPEECH</em>, 2022.Sep
                <br>
                <a href="https://arxiv.org/abs/2206.13691">arXiv</a>
                <p></p>
                <p>
                We propose dummy prototypical networks for few-shot open-set keyword spotting.
                </p>
              </td>
            </tr>

            <tr onmouseout="personalized_stop()" onmouseover="personalized_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='personalized_image'><img src='images/pks.jpg' width="160"></div>
                  <img src='images/pks.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function personalized_start() {
                    document.getElementById('personalized_image').style.opacity = "1";
                  }

                  function personalized_stop() {
                    document.getElementById('personalized_image').style.opacity = "0";
                  }
                  personalized_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2206.13708">
                  <span class="papertitle">Personalized Keyword Spotting through Multi-task Learning</span>
                </a>
                <br>
                Seunghan Yang,
                Byeonggeun Kim,
                <strong>Inseop Chung</strong>,
                Simyung Chang
                <br>
                <em>INTERSPEECH</em>, 2022.Sep
                <br>
                <a href="https://arxiv.org/abs/2206.13708">arXiv</a>
                <p></p>
                <p>
                We propose a multi-task learning approach for personalized keyword spotting.
                </p>
              </td>
            </tr>

            <tr onmouseout="maximizing_stop()" onmouseover="maximizing_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='maximizing_image'><img src='images/uda_ss.jpg' width="160"></div>
                  <img src='images/uda_ss.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function maximizing_start() {
                    document.getElementById('maximizing_image').style.opacity = "1";
                  }

                  function maximizing_stop() {
                    document.getElementById('maximizing_image').style.opacity = "0";
                  }
                  maximizing_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2102.13002">
                  <span class="papertitle">Maximizing Cosine Similarity Between Spatial Features for Unsupervised Domain Adaptation in Semantic Segmentation</span>
                </a>
                <br>
                <strong>Inseop Chung</strong>,
                Daesik Kim,
                Nojun Kwak
                <br>
                <em>WACV</em>, 2022.Jan
                <br>
                <a href="https://arxiv.org/abs/2102.13002">arXiv</a>
                <p></p>
                <p>
                We propose a method to maximize cosine similarity between spatial features for unsupervised domain adaptation in semantic segmentation.
                </p>
              </td>
            </tr>

            <tr onmouseout="multi_stop()" onmouseover="multi_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='multi_image'><img src='images/iccas.jpg' width="160"></div>
                  <img src='images/iccas.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function multi_start() {
                    document.getElementById('multi_image').style.opacity = "1";
                  }

                  function multi_stop() {
                    document.getElementById('multi_image').style.opacity = "0";
                  }
                  multi_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="/">
                  <span class="papertitle">Multi-modal Object Detection, Tracking, and Action Classification for Unmanned Outdoor Surveillance Robots</span>
                </a>
                <br>
                Kyuewang Lee*,
                <strong>Inseop Chung</strong>*,
                Daeho Um,
                Jaeseok Choi,
                Yeji Song,
                Seunghyeon Seo,
                Nojun Kwak,
                Jin Young Choi
                <br>
                <em>ICCAS</em>, 2021.Oct
                <br>
                <p>
                We propose a multi-modal framework for object detection, tracking, and action classification for unmanned outdoor surveillance robots.
                </p>
              </td>
            </tr>

            <tr onmouseout="training_stop()" onmouseover="training_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='training_image'><img src='images/mdod.jpg' width="160"></div>
                  <img src='images/mdod.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function training_start() {
                    document.getElementById('training_image').style.opacity = "1";
                  }

                  function training_stop() {
                    document.getElementById('training_image').style.opacity = "0";
                  }
                  training_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1911.12721">
                  <span class="papertitle">Training Multi-Object Detector by Estimating Bounding Box Distribution for Input Image</span>
                </a>
                <br>
                Jaeyoung Yoo,
                Hojun Lee*,
                <strong>Inseop Chung</strong>*,
                Geonseok Seo,
                Nojun Kwak
                <br>
                <em>ICCV</em>, 2021.Oct
                <br>
                <a href="https://arxiv.org/abs/1911.12721">arXiv</a>
                <p></p>
                <p>
                We propose a method to train multi-object detector by estimating bounding box distribution for input image.
                </p>
              </td>
            </tr>

            <tr onmouseout="fusion_stop()" onmouseover="fusion_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='fusion_image'><img src='images/ffl.jpg' width="160"></div>
                  <img src='images/ffl.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function fusion_start() {
                    document.getElementById('fusion_image').style.opacity = "1";
                  }

                  function fusion_stop() {
                    document.getElementById('fusion_image').style.opacity = "0";
                  }
                  fusion_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/pdf/1904.09058.pdf">
                  <span class="papertitle">Feature Fusion for Online Mutual Knowledge Distillation</span>
                </a>
                <br>
                Jangho Kim,
                Minsugn Hyun,
                <strong>Inseop Chung</strong>,
                Nojun Kwak
                <br>
                <em>ICPR</em>, 2021.Jan
                <br>
                <a href="https://arxiv.org/pdf/1904.09058.pdf">arXiv</a>
                <p></p>
                <p>
                We propose a feature fusion method for online mutual knowledge distillation.
                </p>
              </td>
            </tr>

            <tr onmouseout="feature_stop()" onmouseover="feature_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='feature_image'><img src='images/afd.jpg' width="160"></div>
                  <img src='images/afd.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function feature_start() {
                    document.getElementById('feature_image').style.opacity = "1";
                  }

                  function feature_stop() {
                    document.getElementById('feature_image').style.opacity = "0";
                  }
                  feature_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="http://proceedings.mlr.press/v119/chung20a/chung20a.pdf">
                  <span class="papertitle">Feature-map-level Online Adversarial Knowledge Distillation</span>
                </a>
                <br>
                <strong>Inseop Chung</strong>,
                SeongUk Park,
                Jangho Kim,
                Nojun Kwak
                <br>
                <em>ICML</em>, 2020.Jul
                <br>
                <a href="http://proceedings.mlr.press/v119/chung20a/chung20a.pdf">Proceedings</a>
                <p></p>
                <p>
                We propose feature-map-level online adversarial knowledge distillation.
                </p>
              </td>
            </tr>
          </tbody></table>

          <!-- Patents Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Patents</h2>
                <p>
                  <strong>Domestic Patents</strong>
                </p>
                <ul>
                  <li>Device for Unsupervised Domain Adaptation in Semantic Segmentation Exploiting Inter-pixel Correlations and Driving Method Thereof</li>
                  <br>
                  <li>Device for Regression Scale-aware Cross-domain Object Detection and Driving Method Thereof</li>
                </ul>
                <p>
                  <strong>International Patents</strong>
                </p>
                <ul>
                  <li>Method and Apparatus with Online Task Planning</li>
                  <br>
                  <li>Device and Method for Determining Micro-Action of a Robot based on a Frame image and Natural Language Instruction</li>
                  <br>
                  <li>Multi-Task Learning for For Personalized Keyword Spotting</li>
                  <br>
                  <li>Dummy Prototypical Networks For Few-Shot Open-Set Keyword Spotting</li>
                </ul>
              </td>
            </tr>
          </tbody></table>

          <!-- Funding Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Funding</h2>
                <ul>
                  <li>Samsung Electronics Ph.D. Student Sponsorship Program (2021-2024)</li>
                </ul>
              </td>
            </tr>
          </tbody></table>

          <!-- Honour & Awards Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Honour & Awards</h2>
                <ul>
                  <li>The best paper award in the 3rd Workshop on Real-World Surveillance: Applications and Challenges at WACV2023, $1,000 (2023)</li>
                  <br>
                  <li>BK21 Graduate School Innovation Project Colloquium Outstanding Graduate Student Award, ￦500,000 (2021)</li>
                  <br>
                  <li>Qualcomm Innovation Fellowship Korea 2020 Final Session, Finalist (2020)</li>
                  <br>
                  <li>Samsung Electronics - Seoul National University, Industry-Academic Cooperation Research Award, ￦1,500,000 Won (2020)</li>
                  <br>
                  <li>Special Award, Yonsei Programming Contest 2018 (Spring Semester 2018)</li>
                  <br>
                  <li>Honours, tuition support scholarship, Yonsei University (Spring Semester 2016)</li>
                </ul>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>

    <!-- Acknowledgment Section -->
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding:16px;width:100%;vertical-align:middle;text-align:center;font-size:14px;color:#666;">
          <p>Website template courtesy of <a href="https://jonbarron.info/">Jon Barron</a></p>
        </td>
      </tr>
    </tbody></table>
  </body>
</html>
